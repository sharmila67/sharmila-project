{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sharmila67/sharmila-project/blob/main/object_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "yVw3Oq3JiOHa"
      },
      "outputs": [],
      "source": [
        "#================================================================\n",
        "from ctypes import *\n",
        "import math\n",
        "import random\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import time\n",
        "import darknet\n",
        "from itertools import combinations\n",
        "import pafy\n",
        "import youtube_dl\n",
        "#import image_email_car   # Uncomment for alert to email\n",
        "\n",
        "def is_close(p1, p2):\n",
        "    \"\"\"\n",
        "    #================================================================\n",
        "    # Purpose : Calculate Euclidean Distance between two points\n",
        "    #================================================================\n",
        "    :param:\n",
        "    p1, p2 = two points for calculating Euclidean Distance\n",
        "\n",
        "    :return:\n",
        "    dst = Euclidean Distance between two 2d points\n",
        "    \"\"\"\n",
        "    dst = math.sqrt(p1**2 + p2**2)\n",
        "    #=================================================================#\n",
        "    return dst\n",
        "\n",
        "\n",
        "def convertBack(x, y, w, h):\n",
        "    #================================================================\n",
        "    # Purpose : Converts center coordinates to rectangle coordinates\n",
        "    #================================================================\n",
        "    \"\"\"\n",
        "    :param:\n",
        "    x, y = midpoint of bbox\n",
        "    w, h = width, height of the bbox\n",
        "\n",
        "    :return:\n",
        "    xmin, ymin, xmax, ymax\n",
        "    \"\"\"\n",
        "    xmin = int(round(x - (w / 2)))\n",
        "    xmax = int(round(x + (w / 2)))\n",
        "    ymin = int(round(y - (h / 2)))\n",
        "    ymax = int(round(y + (h / 2)))\n",
        "    return xmin, ymin, xmax, ymax\n",
        "\n",
        "#alert_var = 0      # Uncomment for alert to email       # makes sure that alert (Sending an E-mail) is generated only once\n",
        "\n",
        "def cvDrawBoxes(detections, img):\n",
        "    \"\"\"\n",
        "    :param:\n",
        "    detections = total detections in one frame\n",
        "    img = image from detect_image method of darknet\n",
        "\n",
        "    :return:\n",
        "    img with bbox\n",
        "    \"\"\"\n",
        "    #global alert_var\n",
        "\n",
        "    #================================================================\n",
        "    # Purpose : Filter out Cars class from detections and get\n",
        "    #           bounding box centroid for each car detection.\n",
        "    #================================================================\n",
        "    if len(detections) > 0:  \t\t\t\t\t\t# At least 1 detection in the image and check detection presence in a frame\n",
        "        centroid_dict = dict() \t\t\t\t\t\t# Function creates a dictionary and calls it centroid_dict\n",
        "        objectId = 0\t\t\t\t\t\t\t\t# We inialize a variable called ObjectId and set it to 0\n",
        "        for detection in detections:\t\t\t\t# In this if statement, we filter all the detections for cars only\n",
        "            # Check for the only car name tag\n",
        "            name_tag = str(detection[0].decode())   # Coco file has string of all the names\n",
        "            if name_tag == 'car':\n",
        "                x, y, w, h = detection[2][0],\\\n",
        "                            detection[2][1],\\\n",
        "                            detection[2][2],\\\n",
        "                            detection[2][3]      \t# Store the center points of the detections\n",
        "                xmin, ymin, xmax, ymax = convertBack(float(x), float(y), float(w), float(h))   # Convert from center coordinates to rectangular coordinates, We use floats to ensure the precision of the BBox\n",
        "                # Append center point of bbox for cars detected.\n",
        "                centroid_dict[objectId] = (int(x), int(y), xmin, ymin, xmax, ymax) # Create dictionary of tuple with 'objectId' as the index center points and bbox\n",
        "                objectId += 1 #Increment the index for each detection\n",
        "    #=================================================================#\n",
        "\n",
        "    #=================================================================\n",
        "    # Purpose : Determine which car bbox are close to each other\n",
        "    #=================================================================\n",
        "        vehicle_red_zone_list = [] # List containing which Object id is in under threshold distance condition.\n",
        "        vehicle_red_line_list = []\n",
        "        for (id1, p1), (id2, p2) in combinations(centroid_dict.items(), 2): # Get all the combinations of close detections, #List of multiple items - id1 1, points 2, 1,3\n",
        "            #dx, dy = p1[0] - p2[0], p1[1] - p2[1]  \t# Check the difference between centroid x: 0, y :1\n",
        "            #distance = is_close(dx, dy) \t\t\t# Calculates the Euclidean distance\n",
        "\n",
        "            #if distance < 50.0:\t\t\t\t\t\t# Set our distance threshold - If they meet this condition then..\n",
        "\n",
        "            if not ((p1[2]>=p2[4]) or (p1[4]<=p2[2]) or (p1[5]<=p2[3]) or (p1[3]>=p2[5])):\n",
        "                if id1 not in vehicle_red_zone_list:\n",
        "                    vehicle_red_zone_list.append(id1)       #  Add Id to a list\n",
        "                    vehicle_red_line_list.append(p1[0:2])   #  Add points to the list\n",
        "                if id2 not in vehicle_red_zone_list:\n",
        "                    vehicle_red_zone_list.append(id2)\t\t# Same for the second id\n",
        "                    vehicle_red_line_list.append(p2[0:2])\n",
        "\n",
        "        for idx, box in centroid_dict.items():  # dict (1(key):red(value), 2 blue)  idx - key  box - value\n",
        "            if idx in vehicle_red_zone_list:   # if id is in red zone list\n",
        "                cv2.rectangle(img, (box[2], box[3]), (box[4], box[5]), (255, 0, 0), 2) # Create Red bounding boxes  #starting point, ending point size of 2\n",
        "            else:\n",
        "                cv2.rectangle(img, (box[2], box[3]), (box[4], box[5]), (0, 255, 0), 2) # Create Green bounding boxes\n",
        "\t\t#=================================================================#\n",
        "\n",
        "\t\t#=================================================================\n",
        "    \t# Purpose : Displaying the results and sending an alert message\n",
        "    \t#=================================================================\n",
        "        if len(vehicle_red_zone_list)!=0:\n",
        "            text = \"Crash Detected\"\n",
        "\n",
        "            #Uncomment the below lines for alert to email\n",
        "            #if alert_var == 8:         # makes sure that alert is generated when there are atleast 3 frames which shows that a fall has been detected\n",
        "            #    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "            #    cv2.imwrite('crash_alert.jpg',img)\n",
        "            #    image_email_car.SendMail('crash_alert.jpg')\n",
        "            #alert_var += 1;\n",
        "\n",
        "        else:\n",
        "            text = \"Crash Not Detected\"\n",
        "            #alert_var = 0     #Uncomment for alert to email           # makes sure that alert is generated when there are 3 simultaeous frames of fall detection\n",
        "\n",
        "        location = (10,25)\t\t\t\t\t\t\t\t\t\t\t\t# Set the location of the displayed text\n",
        "        if len(vehicle_red_zone_list)!=0:\n",
        "            cv2.putText(img, text, location, cv2.FONT_HERSHEY_SIMPLEX, 1, (255,0,0), 2, cv2.LINE_AA)  # Display Text\n",
        "        else:\n",
        "            cv2.putText(img, text, location, cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255,0), 2, cv2.LINE_AA)  # Display Text\n",
        "\n",
        "    return img\n",
        "\n",
        "\n",
        "netMain = None\n",
        "metaMain = None\n",
        "altNames = None\n",
        "def YOLO():\n",
        "\n",
        " configPath = \"/content/cfg/yolov4-tiny.cfg\"\n",
        " weightPath = \"your_weight_path_here\"\n",
        " metaPath=\"./cfg/coco.data\"\n",
        " if not os.path.exists(configPath):\n",
        "     raise ValueError(f\"Invalid config path: {os.path.abspath(configPath)}\")\n",
        " if not os.path.exists(weightPath):\n",
        "     raise ValueError(f\"Invalid weight path: {os.path.abspath(weightPath)}\")\n",
        "\n",
        " if not os.path.exists(metaPath):\n",
        "        raise ValueError(\"Invalid data file path `\" +\n",
        "                         os.path.abspath(metaPath)+\"`\")\n",
        " if netMain is None:                                                  # Checks the metaMain, NetMain and altNames. Loads it in script\n",
        "        netMain = darknet.load_net_custom(configPath.encode(\n",
        "            \"ascii\"), weightPath.encode(\"ascii\"), 0, 1)                  # batch size = 1\n",
        " if metaMain is None:\n",
        "        metaMain = darknet.load_meta(metaPath.encode(\"ascii\"))\n",
        " if altNames is None:\n",
        "        try:\n",
        "            with open(metaPath) as metaFH:\n",
        "                metaContents = metaFH.read()\n",
        "                import re\n",
        "                match = re.search(\"names *= *(.*)$\", metaContents,\n",
        "                                  re.IGNORECASE | re.MULTILINE)\n",
        "                if match:\n",
        "                    result = match.group(1)\n",
        "                else:\n",
        "                    result = None\n",
        "                try:\n",
        "                    if os.path.exists(result):\n",
        "                        with open(result) as namesFH:\n",
        "                            namesList = namesFH.read().strip().split(\"\\n\")\n",
        "                            altNames = [x.strip() for x in namesList]\n",
        "                except TypeError:\n",
        "                    pass\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "    #cap = cv2.VideoCapture(0)                                           # Uncomment to use Webcam\n",
        "\n",
        "    #cap = cv2.VideoCapture(\"crash4.mp4\")                                # Uncomment for Local Stored video detection - Set input video\n",
        "\n",
        "    #url = \"https://www.youtube.com/watch?v=isveXCH4NcM\"                 # Uncomment these lines for video from youtube\n",
        "    #video = pafy.new(url)\n",
        "    #best = video.getbest(preftype=\"mp4\")\n",
        "    #cap = cv2.VideoCapture()\n",
        "    #cap.open(best.url)\n",
        "\n",
        "    #cap = cv2.VideoCapture('http://192.168.0.106:4747/mjpegfeed')       # Uncomment for Video from Mobile Camera (DroidCam Hosted Camera)\n",
        "\n",
        " frame_width = int(cap.get(3))                                        # Returns the width and height of capture video\n",
        " frame_height = int(cap.get(4))\n",
        "\n",
        "\n",
        " new_height, new_width = frame_height // 2, frame_width // 2\n",
        "    #print(\"Video Reolution: \",(width, height))\n",
        "\n",
        "    #out = cv2.VideoWriter(\"output.avi\", cv2.VideoWriter_fourcc(*\"MJPG\"), 10.0,  # Uncomment to save the output video    # Set the Output path for video writer\n",
        "            #(new_width, new_height))\n",
        "\n",
        "    # print(\"Starting the YOLO loop...\")\n",
        "\n",
        "    # Create an image we reuse for each detect\n",
        " darknet_image = darknet.make_image(new_width, new_height, 3)         # Create image according darknet for compatibility of network\n",
        "\n",
        " while True:                                                          # Load the input frame and write output frame.\n",
        "        prev_time = time.time()\n",
        "        ret, frame_read = cap.read()\n",
        "        # Check if frame present :: 'ret' returns True if frame present, otherwise break the loop.\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        frame_rgb = cv2.cvtColor(frame_read, cv2.COLOR_BGR2RGB)          # Convert frame into RGB from BGR and resize accordingly\n",
        "        frame_resized = cv2.resize(frame_rgb,\n",
        "                                   (new_width, new_height),\n",
        "                                   interpolation=cv2.INTER_LINEAR)\n",
        "\n",
        "        darknet.copy_image_from_bytes(darknet_image,frame_resized.tobytes())    # Copy that frame bytes to darknet_image\n",
        "\n",
        "        detections = darknet.detect_image(netMain, metaMain, darknet_image, thresh=0.25)    # Detection occurs at this line and return detections, for customize we can change\n",
        "        image = cvDrawBoxes(detections, frame_resized)                   # Call the function cvDrawBoxes() for colored bounding box per class\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        print(1/(time.time()-prev_time))                             # Prints frames per second\n",
        "        cv2.imshow('Demo', image)                                    # Display Image window\n",
        "        cv2.waitKey(3)\n",
        "        #out.write(image)                                            # Write that frame into output video\n",
        "\n",
        " cap.release()                                                    # For releasing cap and out.\n",
        "    #out.release()                                                   # Uncomment to save the output video\n",
        " print(\":::Video Write Completed\")\n",
        "\n",
        " if __name__ == \"__main__\":\n",
        "    YOLO()                                                           # Calls the main function YOLO()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install darknet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3cxqPAyEid8e",
        "outputId": "99d44a11-871c-4885-84c3-54f68b65d951"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting darknet\n",
            "  Downloading darknet-0.3-py3-none-any.whl (4.6 kB)\n",
            "Installing collected packages: darknet\n",
            "Successfully installed darknet-0.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pafy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aosA0K0DiukZ",
        "outputId": "c9e968b1-8567-4c1a-b24f-44d981939294"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pafy in /usr/local/lib/python3.10/dist-packages (0.5.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import youtube_dl"
      ],
      "metadata": {
        "id": "ViWRteehjJBX"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install youtube_dl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MxEcGhOrjXnU",
        "outputId": "e1457e53-3420-46ee-afee-b5226e83755c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: youtube_dl in /usr/local/lib/python3.10/dist-packages (2021.12.17)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "social distance"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "6U-ELJYxMqgC",
        "outputId": "fa74fa4e-ec64-46e4-da5c-039ca42919a5"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (<ipython-input-14-5c5a6907681c>, line 1)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-14-5c5a6907681c>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    social distance\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#================================================================\n",
        "from ctypes import *\n",
        "import math\n",
        "import random\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import time\n",
        "import darknet\n",
        "from itertools import combinations\n",
        "import pafy\n",
        "import youtube_dl\n",
        "\n",
        "def is_close(p1, p2):\n",
        "    \"\"\"\n",
        "    #================================================================\n",
        "    # Purpose : Calculate Euclidean Distance between two points\n",
        "    #================================================================\n",
        "    :param:\n",
        "    p1, p2 = two points for calculating Euclidean Distance\n",
        "\n",
        "    :return:\n",
        "    dst = Euclidean Distance between two 2d points\n",
        "    \"\"\"\n",
        "    dst = math.sqrt(p1**2 + p2**2)\n",
        "    #=================================================================#\n",
        "    return dst\n",
        "\n",
        "\n",
        "def convertBack(x, y, w, h):\n",
        "    #================================================================\n",
        "    # Purpose : Converts center coordinates to rectangle coordinates\n",
        "    #================================================================\n",
        "    \"\"\"\n",
        "    :param:\n",
        "    x, y = midpoint of bbox\n",
        "    w, h = width, height of the bbox\n",
        "\n",
        "    :return:\n",
        "    xmin, ymin, xmax, ymax\n",
        "    \"\"\"\n",
        "    xmin = int(round(x - (w / 2)))\n",
        "    xmax = int(round(x + (w / 2)))\n",
        "    ymin = int(round(y - (h / 2)))\n",
        "    ymax = int(round(y + (h / 2)))\n",
        "    return xmin, ymin, xmax, ymax\n",
        "\n",
        "\n",
        "def cvDrawBoxes(detections, img):\n",
        "    \"\"\"\n",
        "    :param:\n",
        "    detections = total detections in one frame\n",
        "    img = image from detect_image method of darknet\n",
        "\n",
        "    :return:\n",
        "    img with bbox\n",
        "    \"\"\"\n",
        "    #================================================================\n",
        "    # Purpose : Filter out Persons class from detections and get\n",
        "    #           bounding box centroid for each person detection.\n",
        "    #================================================================\n",
        "    if len(detections) > 0:  \t\t\t\t\t\t# At least 1 detection in the image and check detection presence in a frame\n",
        "        centroid_dict = dict() \t\t\t\t\t\t# Function creates a dictionary and calls it centroid_dict\n",
        "        objectId = 0\t\t\t\t\t\t\t\t# We inialize a variable called ObjectId and set it to 0\n",
        "        for detection in detections:\t\t\t\t# In this if statement, we filter all the detections for persons only\n",
        "            # Check for the only person name tag\n",
        "            name_tag = str(detection[0].decode())   # Coco file has string of all the names\n",
        "            if name_tag == 'person':\n",
        "                x, y, w, h = detection[2][0],\\\n",
        "                            detection[2][1],\\\n",
        "                            detection[2][2],\\\n",
        "                            detection[2][3]      \t# Store the center points of the detections\n",
        "                xmin, ymin, xmax, ymax = convertBack(float(x), float(y), float(w), float(h))   # Convert from center coordinates to rectangular coordinates, We use floats to ensure the precision of the BBox\n",
        "                # Append center point of bbox for persons detected.\n",
        "                centroid_dict[objectId] = (int(x), int(y), xmin, ymin, xmax, ymax) # Create dictionary of tuple with 'objectId' as the index center points and bbox\n",
        "                objectId += 1 #Increment the index for each detection\n",
        "    #=================================================================#\n",
        "\n",
        "    #=================================================================\n",
        "    # Purpose : Determine which person bbox are close to each other\n",
        "    #=================================================================\n",
        "        red_zone_list = [] # List containing which Object id is in under threshold distance condition.\n",
        "        red_line_list = []\n",
        "        for (id1, p1), (id2, p2) in combinations(centroid_dict.items(), 2): # Get all the combinations of close detections, #List of multiple items - id1 1, points 2, 1,3\n",
        "            dx, dy = p1[0] - p2[0], p1[1] - p2[1]  \t# Check the difference between centroid x: 0, y :1\n",
        "            distance = is_close(dx, dy) \t\t\t# Calculates the Euclidean distance\n",
        "            if distance < 75.0:\t\t\t\t\t\t# Set our social distance threshold - If they meet this condition then..\n",
        "                if id1 not in red_zone_list:\n",
        "                    red_zone_list.append(id1)       #  Add Id to a list\n",
        "                    red_line_list.append(p1[0:2])   #  Add points to the list\n",
        "                if id2 not in red_zone_list:\n",
        "                    red_zone_list.append(id2)\t\t# Same for the second id\n",
        "                    red_line_list.append(p2[0:2])\n",
        "\n",
        "        for idx, box in centroid_dict.items():  # dict (1(key):red(value), 2 blue)  idx - key  box - value\n",
        "            if idx in red_zone_list:   # if id is in red zone list\n",
        "                cv2.rectangle(img, (box[2], box[3]), (box[4], box[5]), (255, 0, 0), 2) # Create Red bounding boxes  #starting point, ending point size of 2\n",
        "            else:\n",
        "                cv2.rectangle(img, (box[2], box[3]), (box[4], box[5]), (0, 255, 0), 2) # Create Green bounding boxes\n",
        "\t\t#=================================================================#\n",
        "\n",
        "\t\t#=================================================================\n",
        "    \t# Purpose : Display Risk Analytics and Show Risk Indicators\n",
        "    \t#=================================================================\n",
        "        text = \"People at Risk: %s\" % str(len(red_zone_list)) \t\t\t# Count People at Risk\n",
        "        location = (10,25)\t\t\t\t\t\t\t\t\t\t\t\t# Set the location of the displayed text\n",
        "        cv2.putText(img, text, location, cv2.FONT_HERSHEY_SIMPLEX, 1, (246,86,86), 2, cv2.LINE_AA)  # Display Text\n",
        "\n",
        "        for check in range(0, len(red_line_list)-1):\t\t\t\t\t# Draw line between nearby bboxes iterate through redlist items\n",
        "            start_point = red_line_list[check]\n",
        "            end_point = red_line_list[check+1]\n",
        "            check_line_x = abs(end_point[0] - start_point[0])   \t\t# Calculate the line coordinates for x\n",
        "            check_line_y = abs(end_point[1] - start_point[1])\t\t\t# Calculate the line coordinates for y\n",
        "            if (check_line_x < 75) and (check_line_y < 25):\t\t\t\t# If both are We check that the lines are below our threshold distance.\n",
        "                cv2.line(img, start_point, end_point, (255, 0, 0), 2)   # Only above the threshold lines are displayed.\n",
        "        #=================================================================#\n",
        "    return img\n",
        "\n",
        "\n",
        "netMain = None\n",
        "metaMain = None\n",
        "altNames = None\n",
        "\n",
        "def YOLO():\n",
        "\n",
        "  global metaMain, netMain, altNames\n",
        "  configPath = \"./content/cfg/yolov4-tiny.cfg\"                                 # Path to cfg\n",
        "  weightPath = \"./yolov4-tiny.weights\"                                 # Path to weights\n",
        "  metaPath = \"./cfg/coco.data\"                                         # Path to meta data\n",
        "  if not os.path.exists(configPath):                                   # Checks whether file exists otherwise return ValueError\n",
        "        raise ValueError(\"Invalid config path `\" + os.path.abspath(configPath)+\"`\")\n",
        "  if not os.path.exists(weightPath):\n",
        "        raise ValueError(\"Invalid weight path `\" +  os.path.abspath(weightPath)+\"`\")\n",
        "  if not os.path.exists(metaPath):\n",
        "        raise ValueError(\"Invalid data file path `\" +  os.path.abspath(metaPath)+\"`\")\n",
        "  if netMain is None:                                                  # Checks the metaMain, NetMain and altNames. Loads it in script\n",
        "        netMain = darknet.load_net_custom(configPath.encode(\n",
        "            \"ascii\"), weightPath.encode(\"ascii\"), 0, 1)                  # batch size = 1\n",
        "  if metaMain is None:\n",
        "        metaMain = darknet.load_meta(metaPath.encode(\"ascii\"))\n",
        "  if altNames is None:\n",
        "        try:\n",
        "            with open(metaPath) as metaFH:\n",
        "                metaContents = metaFH.read()\n",
        "                import re\n",
        "                match = re.search(\"names *= *(.*)$\", metaContents,\n",
        "                                  re.IGNORECASE | re.MULTILINE)\n",
        "                if match:\n",
        "                    result = match.group(1)\n",
        "                else:\n",
        "                    result = None\n",
        "                try:\n",
        "                    if os.path.exists(result):\n",
        "                        with open(result) as namesFH:\n",
        "                            namesList = namesFH.read().strip().split(\"\\n\")\n",
        "                            altNames = [x.strip() for x in namesList]\n",
        "                except TypeError:\n",
        "                    pass\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "    #cap = cv2.VideoCapture(0)                                           # Uncomment to use Webcam\n",
        "\n",
        "    #cap = cv2.VideoCapture(\"Video_for_Testing.mp4\")                     # Uncomment for Local Stored video detection - Set input video\n",
        "\n",
        "    #url = \"https://www.youtube.com/watch?v=isveXCH4NcM\"                 # Uncomment these lines for video from youtube\n",
        "    #video = pafy.new(url)\n",
        "    #best = video.getbest(preftype=\"mp4\")\n",
        "    #cap = cv2.VideoCapture()\n",
        "    #cap.open(best.url)\n",
        "\n",
        "    #cap = cv2.VideoCapture('http://192.168.0.106:4747/mjpegfeed')       # Uncomment for Video from Mobile Camera (DroidCam Hosted Camera)\n",
        "\n",
        "  frame_width = int(cap.get(3))                                        # Returns the width and height of capture video\n",
        "  frame_height = int(cap.get(4))\n",
        "  new_height, new_width = frame_height // 2, frame_width // 2\n",
        "    #print(\"Video Reolution: \",(width, height))\n",
        "\n",
        "    #out = cv2.VideoWriter(\"output.avi\", cv2.VideoWriter_fourcc(*\"MJPG\"), 10.0,  # Uncomment to save the output video    # Set the Output path for video writer\n",
        "            #(new_width, new_height))\n",
        "\n",
        "    # print(\"Starting the YOLO loop...\")\n",
        "\n",
        "    # Create an image we reuse for each detect\n",
        "  darknet_image = darknet.make_image(new_width, new_height, 3)         # Create image according darknet for compatibility of network\n",
        "\n",
        "  while True:                                                          # Load the input frame and write output frame.\n",
        "        prev_time = time.time()\n",
        "        ret, frame_read = cap.read()\n",
        "        # Check if frame present :: 'ret' returns True if frame present, otherwise break the loop.\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        frame_rgb = cv2.cvtColor(frame_read, cv2.COLOR_BGR2RGB)          # Convert frame into RGB from BGR and resize accordingly\n",
        "        frame_resized = cv2.resize(frame_rgb,\n",
        "                                   (new_width, new_height),\n",
        "                                   interpolation=cv2.INTER_LINEAR)\n",
        "\n",
        "        darknet.copy_image_from_bytes(darknet_image,frame_resized.tobytes())    # Copy that frame bytes to darknet_image\n",
        "\n",
        "        detections = darknet.detect_image(netMain, metaMain, darknet_image, thresh=0.25)    # Detection occurs at this line and return detections, for customize we can change\n",
        "        image = cvDrawBoxes(detections, frame_resized)                   # Call the function cvDrawBoxes() for colored bounding box per class\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        print(1/(time.time()-prev_time))                                 # Prints frames per second\n",
        "        cv2.imshow('Demo', image)                                        # Display Image window\n",
        "        cv2.waitKey(3)\n",
        "        #out.write(image)                                                # Write that frame into output video\n",
        "\n",
        "  cap.release()                                                        # For releasing cap and out.\n",
        "    #out.release()                                                       # Uncomment to save the output video\n",
        "  print(\":::Video Write Completed\")\n",
        "\n",
        "\n",
        "  if __name__ == \"__main__\":\n",
        "    YOLO()                                                               # Calls the main function YOLO()"
      ],
      "metadata": {
        "id": "7xF6ulVNM6IQ"
      },
      "execution_count": 17,
      "outputs": []
    }
  ]
}